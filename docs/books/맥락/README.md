![로고](./sample.jpg) <조만간 로고는 업로드>


## 1. 랩 이름이 뭔가요?
맥락 [Context]

## 2. 랩 이름을 왜 이렇게 지었나요?
영상이 무엇을 뜻하고 말하고자 하는지 알아내자는 의미에서 맥락이라고 지었던것 같습니다.

## 3. 랩원들을 소개해 주세요.

강우람 / 랩장 : 영상기반 감정인식부터 이미지 해설관련 연구까지 다양한 연구과제에 참여 해 보았고 간단한 머신 설계에서부터 딥러닝기반 모델의 설계까지 두루 관심을 가지고 공부하고 있습니다.  연구라는 것이 단지 랩안의 데이터로만 끝나는게 아니라 실제 환경으로의 적용되는 기술과 세상을 널리 이롭게 만드는 기술 개발에 관심이 많습니다.

김준화 / 연구원 : 학부 재학 중 우연한 기회로 alexnet을 접하게 되어 딥러닝에 빠진 학생입니다. 현재 디지털영상처리 연구실에서 영상 관련 공부와 함께 딥러닝 공부와 연구를 진행하고 있습니다. 연구실 동료들 이외에 다른 연구실 연구자들과 교류하고 싶어서 계속 참여하고 있습니다. 

도미래 / 연구원 : 인공지능 분야 교수님 아래에서 학부 연구생으로 연구를 진행하고 있습니다. 다양한 분야를 시도하는 도중 GAN과 자연어 처리, 이미지 처리를 결합하여 연구를 진행하는 팀을 알게되어 흥미가 생겨 참여하게 되었습니다.  또한 다양한 분야의 사람들과 연구를 진행하는 것이 정말 재미있을 것같아 참여하게 되었습니다.

김현우 / 연구원 : 선린인터넷고등학교에 입학하여 다양한 개발공부를 하며 진로를 고민하던 중, 인공지능에 관심이 생겨 찾아보다가 머신러닝 분야를 알게 되었고, 미래에 원하는 인공지능들을 자유롭게 개발하는 목표를 갖고 딥러닝을 공부하기 시작했습니다. 처음에는 딥러닝을 단순한 코드로 접해 코드 위주의 개발공부만 했었습니다. 하지만 다양한 종류의 딥러닝 알고리즘을 접하면서 원리, 이론도 깊게 공부할 수 있고, 다양한 경험도 쌓을 수 있는 기회가 될 것 같아서  비록 고등학생이지만, 이 곳에 참여하게 되었습니다.

홍은영 / 연구원 :딥러닝에 관심이 생겨 GAN에 대해 알게 되었습니다. 코드나 딥러닝에 대해 미숙한 수준이지만 조금씩 공부하면서 실력을 키우고 싶습니다.

김인수 / 연구원 : 소소하거나 마법 같은 응용 딥러닝 알고리즘 개발이 목표입니다. GAN에 매력을 느껴 랩에 참여했습니다. 지금은 신호처리도 기초부터 공부중입니다. 2019년 개인적 목표는 컴퓨터 음악 작곡이고, 2019년 랩 활동의 목표는 GAN 논문을 연대순으로 스크래치부터 구현하는 것입니다. 중요한 딥러닝 기초개념들을 다시 공부중인데 너무 할 게 많아서 공부 진도가 안 나가는 중.

최원조 / 연구원 : 게임개발자였으며, 인공지능 분야에 발을 들인지는 오래되지 않았습니다. Reinforcement Learning을 이용한 게임플레이 에이전트를 만들기 시작하면서 분야에 발을 들였습니다. 현재는 자연어처리쪽에서 일하며 해당 분야에 대해 공부하고있습니다. 현재 관심사는 자연어생성입니다. 잘부탁드립니다.

장광훈 / 연구원 : 미디어 콘텐츠 산업에 종사하고 있습니다. Vision생성, 자연어 인식/생성과 3D image mapping에 많은 관심을 가지고 있습니다. 현재는 GAN을 통한 조건적 이미지 생성에 관해 공부하고 있습니다.

신정규 / 연구원 : 영상 하이라이트 검출, cuda를 이용한 nucleotide BLAST 가속 등 다양한 분야의 데이터와 모델을 다뤄본 경험이 있으며, 현재는 문서 요약 알고리즘을 연구하고 있습니다. 어떤 분야든 가리지 않고 연구하는 것에 관심이 많습니다. 다양한 의견을 나누고, 새로운 분야에 대해 공부하고 싶어 참여하게 되었습니다.


## 4. 랩 주제는 뭔가요?  

생성모델을 이용한 Text2Image
생성모델, 텍스트 투 이미지 ...
인공지능 공모전 참여...
고문서 복원

랩 맥락은 Image caption, GAN 분야로 관심을 끌고 있는 영상을 해설하는 분야에 대해 연구를 진행하기 위해 모인 팀으로 관련 논문 학습, 재현과 더불어 연구과정중 계속해서 새로운 아이디어를 추구 ,시도해보기 위해 모였습니다. 

소개링크 : https://github.com/labcontext/Introduction

한국인공지능연구소 산하 GAN과 관련된 연구를 진행하고 있는 LAB 맥락은 직장인, 대학(원)생 등 10명으로 구성되있는 연구그룹입니다.
각자 서로 다른 배경에서 인공지능이라는 주제를 공부하고 연구하고 실험해보고자 모였습니다.   2018년도 4분기
https://www.ai-lab.kr/labs/maegrag-raebjang-ganguram

2019년도 1분기
https://www.ai-lab.kr/labs/maegrag-raebjang-ganguram-1
2019년도 2분기
https://www.ai-lab.kr/labs/maegrag-raebjang-ganguram-2
주 연구 주제는 text to image와 image to text의 연결과 관련된 공부와 시도를 해보고있습니다. text to image와 image to text중에서 진행중인 이슈는 text to image 관련 이슈로 다양한 GAN을 이용한 text to image 구현 등을 시도 하고있습니다.
최근에 cross domain 관련한 GAN 논문들이 나오고 있습니다. 특히 {영상} <=> {영상}, {자연어} <=> {자연어} 식의 구조의 논문들이 나오고 있는데 그렇다면 cross modality, 서로 다른 모달리티를 갖는 두 집합에 대한 연결, {영상 => 자연어} <=> {자연어 => 영상} 의 두 generative model 끼리의 연결은 어떻게 구현해볼수 있을까 하는 주제에 관심을 갖고 있습니다. 매우 재미있어보이는 주제 라고 생각하여 진행하고있습니다.
연구그룹내 소과제로써 관련 논문, 자료 문서화 작업을 병행중에 있습니다.

## 5. 랩 주제를 설명해주세요.
(이 주제에 관심을 갖게 된 이유는 뭔가요?)


text와 image, 생성모델 다양한 인공지능 분야를 같이 경험해볼수있는 주제이기 때문에 처음에 선정하게 된것같습니다. 
현재는 생성모델 중 GAN을 활용하여 text to image 태스크를 수행하고 있습니다. GAN은  다양한 분야에 활용이 가능하고 다양한 모델의 구조를 시도해볼 수 있고 추후 확장가능성이 크기 때문입니다.    

## 6. 랩 결성 초반의 연구활동 계획은 무엇이었나요?


초반 연구활동에서는 image description, image caption 분야로 관심을 끌고 있는 영상을 해설하는 분야에 대해 연구를 진행하는 것을 목표로 관련 논문 학습 재현과 더불어 연구과정중 계속해서 새로운 아이디어를 추구 시도해보기 위해 모였습니다. 

## 7. 중반 이후 연구방향이나 활동에 변화가 있었나요?

초반 활동에서 Image caption과 text to image GAN 분야에 관심을 갖고 연구를 진행하며  관련 논문 학습 및 재현 그리고 기초공부를 진행했습니다. 연구 과정중 새로운 아이디어를 추구, 시도하며 팀원들의 사기를 고취하기 위해 논문 이외의 활동을 추가하여 진행하는 것으로 변경했습니다.  활동의 변화를 통해 해커톤, 공모전, 프로젝트를 진행했고 다음 기수에는 ‘고문서 복원’이라는 하나의 주제를 목표로 프로젝트를 진행하고자 합니다. 
 
## 8. 랩 모임을 하면서 에피소드가 있었다면?


에피소드? 
오천원 결제시 볼수있음 |Il|Il|IlIl|Il|l|IlIl| [바코드] 

회의중에 재미로 고문서 복원 이야기를 꺼냈다가 모두 좋은 아이디어라 생각해서 매주 회의마다 남는 시간에 해당 아이디어를 구체화하기 시작했고, NIPA에서 진행하는 고성능 컴퓨터사업에 선정되어 다음 기수 활동 목표로 진행하게 되었습니다.

첫 기수때의  주요 활동 내용은 논문 리딩이였는데 당시 팀원분들이 할당량에 대한 부담감을 느끼고 매 한달마다 한분씩 너무 포기하고 나가서 2명이 남게 되어 한번 위기를 맞았던 적이 있음 시간이 지날수록 뜻이 맞는 사람끼리 모여서 첫기수부터 지금까지 일년 정도 지난 현 시점 10명정도 같이 연구하고 공모전에도 참가해보고 있음

## (9+10). 연구를 위해 어떤 데이터들을 사용하였고 어떻게 확보하였나요?
알려진 오픈데이터 CIFAR-10, MSCOCO 등을 사용하였으며, 검색을 통해 확보하였습니다.

## 11. 모델링은 어떻게 했나요?

-      첫번째 실험
DCGAN / BatchNormalization / SGD 이용하여 모델링를 진행했고  학습이 진행되는 과정에서 mode collapse발생했습니다. 

-      두번째 실험
더 딥한 DCGAN 이용 / batchnormaliztion / SGD 이용했고  mode collapse가 더 빨리 찾아왔습니다. 아마도 일반적 GAN설계에서  마지막 activation function에서는 tanh로 사용하지만 , 최초 모델에서는 모델이 얕고 필터가 컸기 때문에 마지막 레이어를 제외한 레이어의 activation function을 tanh로 써도 학습에 무리가 없지만 모델이 깊어짐에 따라 Vanishing gradient problem이 발생한 것으로 보입니다.

-      세번째 실험
DCGAN을 기반으로 image to image translation분야에서 시도되는 여러 스킬을 조합해보았습니다. 
 batchnormalizantion 를 Instance normalization으로 변경
 SGD 를 Adam 으로 변경.
 모델의 깊이는 최초모델과 비슷한 수준으로 줄이고 필터사이즈를 늘렸음.
Instance normalization으로 변경한 이유는 cross domain GAN과 관련된 시도에서 batchnormalizaiotn으로 들어오는 노이즈가 GAN학습에 어떠한 영향을 끼칠지 장담하지 못하는 분위기인 것으로 보여 그 대용으로 사용사용한 것이며 전반적인 개선이 있었습니다. 

-      네번 째 실험
세번째 모델을 토대로 image size와 resolution을 키우는 GAN 또는 VAE를 스택하려는 것을 시도 하려 했으나, 컴퓨팅 파워문제가 발생했습니다. 그래서 output feature를 64*64로하며 이를 다시 input으로 받아 사이즈를 키우는 모델을 stack하여 stackGan형태로 만드는 것을 목표로 설정했습니다. 

-      다섯번 째 실험
CVPRFLOWER 데이터를 활용하여 꽃사진과 꽃설명을 가지고 학습을 진행해보았습니다. SNGAN을 이용하여 설계하였으며 D부분을 SNGAN형태로, G부분을 deep convolutional하게 설계하였습니다. 기존 시도와는 다르게 G에서 앞 단 convolution 레이어에 입력하기 전에 한번 normalizaion을 해주고 매 convolution 레이어 이후에 넣었던 normalization 부분을 여러 실험을 통해 빼 보았으며, activation 부분을 tanh로 바꾸어 학습을 진행했습니다. 

5번의 실험을 진행하는 동안 
mode collpase와 기존 모델들이 쓰던 sentence embedding의 한계와 같은 이슈가 발생했습니다.  


## 12. 다음의 랩 결과물에 대해 설명해주세요. (코드와 설명)


Azure 공모전 : 
랩 내에서 팀을 나눠서 Azure에서 주관 주최하는 국제 공모전에 지원, 1팀은 Deep Learning Api를 활용, 영상에 자동으로 워드클라우드 북마크를 달아 주는 서비스를 개발했다.
2팀은 회의록 작성 AI를 개발했다.
1팀, 2팀 모두 Azure 공모전 본선 진출하였고 최종 결과를 기다리는 중.

Azure 공모전 context cloud :
https://github.com/labcontext/context-cloud-on-azure

 video indexer에 등록된 영상을 이용하여 해당 동영상의 키워드를 추출 및 키워드에 해당하는 시간으로 이동 및 웃긴 부분을 추출하여 웃긴 부분으로 이동할 수 있는 서비스를 제공하는 웹서비스입니다.  기존 동영상 스트리밍 서비스에서 손수 타임스탬프를 제작해야했던 번거로움을 줄여주는 서비스를 제작했습니다. 

Azure 공모전 Minutes-recorder :
 https://github.com/labcontext/Minutes-record-AI

 회의록을 음성인식기술을 기반으로 자동으로 작성하는 서비스를 개발해보았는데 최종적으로 음성인식단과 안드로이드단을 합치는 부분은 올리지 못하였고 그럼에도 불구하고 공모전을 진행간 많은 것을 배울수 있었는데 회의록작성하는 시간이나 소요를 줄여주는 서비스를 기획 개발해 볼수 있었고 프론트엔드와 백엔드 개발을 같이 경험해보았습니다.

SNGAN을 활용한 Text to image GAN 성능 개선 :
https://github.com/labcontext/text-to-image-with-SNGAN-and-WGAN

   기존 DCGAN을 베이스라인으로 가져가는 Text-to-image Sysnthesis 논문을 재현한 코드들과 그 실행결과물들에 근본적으로 DCGAN이 갖고 있는 문제를 그대로 답습하여 발생하여 그 성능을 개선해보고 더 큰 resolution에 대응하는 GAN생성모델을 만들기 위해 SNGAN을 기반으로 코드를 일부 수정하였고 WGAN도 적응해보려고 코드는 작성하였은나 WGAN 특성상 학습에 시간이 오래걸려 나중으로 미루었습니다.
   SNGAN을 통해 더 고해상도의 영상을 얻을수있었고 위 링크를 통해 관련 작업했던 코드를 실행시켜 볼수 있고 관련하여 참고했던 논문 리스트또한 관련 링크로 달아 놓았습니다. text to image 생성모델을 공부하고 싶은 분들에게 참고자료로 남겨놓았습니다.
   다양한 GAN 모델을 시도하던중 기존에 모델에서 사용하던 word embedding, sentence embedding의 한계점을 체감하여 관련 공부를 추가적으로 더 진행하게 되는 계기가 되었습니다. 


 residual attention과 Universial sentence embedding을 이요한 Text to image GAN 성능 개선
https://github.com/labcontext/text-to-image-with-residual-attention-and-USE 
<<내용 추가 예정>>

## 13. 랩원들의 후기를 부탁합니다.


강우람 : 약 1년간 맥락을 만들고 같이 만들어가며 많은 공부를 해볼수 있었고 다양한 논문을 읽어보고 공모전, 대회 등도 같이 참여해보며 많은 추억과 경험을 만들수 있었습니다. 

김인수 : 같이 책을 쓰면서 두기수간 몸담고 있던 우리 맥락랩에 대해서 더 잘 알아보는 시간이 된 것 같다. 야망의 맥락 더 흥하자! ㅋㅋ

도미래 : 단순히 GAN에 대해 관심이 있어 맥락에 들어오게 되었는데 다양한 직업과 연령대의 팀원들과 활동하면서 재미있는 추억을 쌓은 것같습니다. 추천추천 ^^ 

김현우 : 처음 맥락에 참여하면서, 갓직히 혼자 고등학생으로 참여하게 되어, 다른 팀원분들을 잘 따라갈 수 있을까 하며 걱정이 앞서긴 했지만, 무조건 최선을 다 하자는 마인드로 열정적으로 참여했습니다. 몸은 힘들었지만 몇 개월간 참여하면서 스스로 성장한 것 같아 참여한 것에 대해 정말 만족합니다. 맥락에서 공부하며 혼자 공부했으면 힘들었을법한 부분들도 팀원분들께서 잘 짚어주시고 도와주셔서 큰 도움이 되었고, 정기 모임 및 대회 참여 등 경험도 쌓을 수 있어 정말 좋았습니다. 이젠 가족같은 팀이 되어 그 동안의 활동들도 하나의 경험이자 추억이 되었고 앞으로도 쭊쭊 더 잘되길 빕니당 호호홓
